# main attack script placeholder
import os
import torch
from transformers import AutoTokenizer
from llava.model import LlavaLlamaForCausalLM
from watermark_vocab import get_green_red_vocab
from watermark_sampling import apply_watermark_bias
from watermark_detector import detect_green_ratio
from extract_hidden import extract_hidden_features
from compute_nullspace import compute_nullspace_basis
from apply_projection import project_hidden  # å®ç°ä¸º hook function

# ==== é…ç½®å‚æ•° ====
image_path = "data/coco_sample/0000001.jpg"
prompt = "Describe what's in the image."
blurred_image_path = "data/coco_sample/0000001_blur.jpg"
model_name = "liuhaotian/llava-v1.5-7b"
layer_idx = 10
gamma = 2.0
k = 16

# ==== åŠ è½½æ¨¡å‹å’Œ tokenizer ====
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = LlavaLlamaForCausalLM.from_pretrained(model_name).cuda().eval()

# ==== æ„å»º green token vocab ====
green_vocab, _ = get_green_red_vocab(tokenizer, ratio=0.5)

# ==== åŸå§‹ç”Ÿæˆï¼ˆæœ‰æ°´å°ï¼‰ ====
def generate_with_watermark(prompt, image_tensor):
    inputs = model.processor(images=image_tensor, text=prompt, return_tensors="pt").to("cuda")
    past = None
    output_tokens = []

    for _ in range(50):
        if output_tokens:
            input_ids = torch.tensor([[output_tokens[-1]]]).to("cuda")
        else:
            input_ids = inputs.input_ids

        out = model(input_ids=input_ids, past_key_values=past, use_cache=True)
        logits = out.logits[:, -1, :]
        past = out.past_key_values

        logits = apply_watermark_bias(logits, tokenizer, green_vocab, gamma)
        next_token = torch.argmax(logits, dim=-1)
        output_tokens.append(next_token.item())

        if next_token.item() == tokenizer.eos_token_id:
            break

    return tokenizer.decode(output_tokens, skip_special_tokens=True)

# ==== æå–æ­£è´Ÿç‰¹å¾ ====
extract_hidden_features(image_path, prompt, "features/pos.pt", layer_idx)
extract_hidden_features(blurred_image_path, prompt, "features/neg.pt", layer_idx)

# ==== è®¡ç®— null space åŸºæ–¹å‘ ====
X_pos = torch.load("features/pos.pt")
X_neg = torch.load("features/neg.pt")
E = X_pos - X_neg
V_k = compute_nullspace_basis(E, k=k)
torch.save(V_k, "features/nullspace.pt")

# ==== æ³¨å†Œ forward hook æ”»å‡» ====
def hook_fn(module, input, output):
    out_proj = project_hidden(output, V_k)
    return out_proj

handle = model.model.layers[layer_idx].mlp.fc1.register_forward_hook(hook_fn)

# ==== æ”»å‡»åé‡æ–°ç”Ÿæˆ ====
from PIL import Image
from torchvision import transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
img = Image.open(image_path).convert("RGB")
image_tensor = transform(img).unsqueeze(0).cuda()

print("\nğŸ”° Watermarked output:")
orig_text = generate_with_watermark(prompt, image_tensor)
print(orig_text)
ratio_orig = detect_green_ratio(orig_text, green_vocab)
print(f"âœ… Green token ratio: {ratio_orig:.3f}")

print("\nğŸ’¥ After NullWM attack:")
handle.remove()  # é˜²æ­¢å åŠ 
model = LlavaLlamaForCausalLM.from_pretrained(model_name).cuda().eval()
handle = model.model.layers[layer_idx].mlp.fc1.register_forward_hook(hook_fn)
attacked_text = generate_with_watermark(prompt, image_tensor)
print(attacked_text)
ratio_attacked = detect_green_ratio(attacked_text, green_vocab)
print(f"âŒ Green token ratio after attack: {ratio_attacked:.3f}")
